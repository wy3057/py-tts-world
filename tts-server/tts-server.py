import sys
import subprocess
import os
from pathlib import Path
import time
import platform
import simplejson as json
import logging
import uuid
from typing import Optional, Dict, Any
from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import uvicorn
import soundfile as sf
import torch
import pkg_resources
from pkg_resources import DistributionNotFound, VersionConflict
from modelscope.utils.constant import Tasks
from modelscope.pipelines import pipeline
from modelscope import snapshot_download
from modelscope.pipelines.base import Pipeline
from modelscope.pipelines.builder import PIPELINES
from modelscope.models.base import Model, TorchModel
from modelscope.models.builder import MODELS
import sortedcontainers as sc

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def print_step(msg):
    """æ‰“å°å¸¦æœ‰æ ·å¼çš„æ­¥éª¤ä¿¡æ¯"""
    logger.info(f"\nğŸ”¹ {msg}")

def print_success(msg):
    """æ‰“å°å¸¦æœ‰æ ·å¼çš„æˆåŠŸä¿¡æ¯"""
    logger.info(f"\nâœ… {msg}")

def print_error(msg):
    """æ‰“å°å¸¦æœ‰æ ·å¼çš„é”™è¯¯ä¿¡æ¯"""
    logger.error(f"\nâŒ {msg}")

def check_python():
    """æ£€æŸ¥Pythonç¯å¢ƒ"""
    print_step("æ£€æŸ¥Pythonç¯å¢ƒ...")
    if sys.version_info < (3, 8):
        print_error("éœ€è¦Python 3.8æˆ–æ›´é«˜ç‰ˆæœ¬")
        logger.error("è¯·è®¿é—® https://www.python.org/downloads/ ä¸‹è½½æ–°ç‰ˆPython")
        sys.exit(1)
    print_success("Pythonç‰ˆæœ¬æ£€æŸ¥é€šè¿‡")

def install_package(package: str):
    """å®‰è£…æŒ‡å®šçš„åŒ…"""
    try:
        logger.info(f"æ­£åœ¨å®‰è£… {package}...")
        subprocess.run([sys.executable, "-m", "pip", "install", package], check=True)
    except subprocess.CalledProcessError:
        logger.error(f"{package} å®‰è£…å¤±è´¥")
        sys.exit(1)

def update_package(package: str):
    """æ›´æ–°æŒ‡å®šçš„åŒ…"""
    try:
        logger.info(f"æ­£åœ¨æ›´æ–° {package}...")
        subprocess.run([sys.executable, "-m", "pip", "install", "--upgrade", package], check=True)
    except subprocess.CalledProcessError:
        logger.error(f"{package} æ›´æ–°å¤±è´¥")
        sys.exit(1)

def check_and_install_dependencies():
    """æ£€æŸ¥å¹¶å®‰è£…ç¼ºå¤±çš„ä¾èµ–åŒ…"""
    print_step("æ£€æŸ¥ä¾èµ–åŒ…...")

    requirements = {
        "modelscope": ">=1.9.5,<2.0.0",
        "torch": ">=2.0.0",
        "torchaudio": "",
        "soundfile": "",
        "scipy": "",
        "fastapi": "",
        "uvicorn": "",
        "python-multipart": "",
        "pydantic": "<2.0",
        "transformers": "",
        "datasets": "",
        "addict": ""
    }

    missing_packages = []
    update_packages = []

    for package, version in requirements.items():
        requirement = f"{package}{version}" if version else package
        try:
            pkg_resources.require(requirement)
        except DistributionNotFound:
            missing_packages.append(package)
        except VersionConflict:
            if version:
                update_packages.append(requirement)

    if not missing_packages and not update_packages:
        print_success("æ‰€æœ‰ä¾èµ–åŒ…å·²å®‰è£…ä¸”ç‰ˆæœ¬æ­£ç¡®")
        return

    if missing_packages:
        print_step(f"å®‰è£…ç¼ºå¤±çš„åŒ…: {', '.join(missing_packages)}")
        for package in missing_packages:
            install_package(package)

    if update_packages:
        print_step(f"æ›´æ–°ç‰ˆæœ¬ä¸åŒ¹é…çš„åŒ…: {', '.join(update_packages)}")
        for package in update_packages:
            update_package(package)

    print_success("ä¾èµ–åŒ…æ£€æŸ¥å’Œå®‰è£…å®Œæˆ")

@MODELS.register_module('text-to-speech', module_name='hoyotts')
class HoyoTTSModel(TorchModel):
    def __init__(self, model_dir, *args, **kwargs):
        super().__init__(model_dir, *args, **kwargs)
        self.model_dir = model_dir
        config_path = os.path.join(model_dir, 'config.json')
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
        self.sampling_rate = self.config['data']['sampling_rate']
        self.spk2id = self.config['data']['spk2id']
        self.duration_model_path = os.path.join(model_dir, 'DUR_78000.pth')
        self.acoustic_model_path = os.path.join(model_dir, 'D_78000.pth')
        self.vocoder_model_path = os.path.join(model_dir, 'G_78000.pth')

    def forward(self, text, voice_name):
        if voice_name not in self.spk2id:
            raise ValueError(f"æœªçŸ¥çš„è¯´è¯äºº: {voice_name}")
        speaker_id = self.spk2id[voice_name]
        audio_length = int(self.sampling_rate * 3)  # 3ç§’çš„éŸ³é¢‘
        return torch.randn(audio_length)

@PIPELINES.register_module('text-to-speech', module_name='hoyotts-speech-generation')
class HoyoTTSPipeline(Pipeline):
    def __init__(self, model_dir, **kwargs):
        super().__init__(model=model_dir, **kwargs)
        self.model = HoyoTTSModel(model_dir)
        self.device = kwargs.get('device', 'cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)

    def preprocess(self, inputs):
        if isinstance(inputs, (list, tuple)):
            if len(inputs) != 2:
                raise ValueError('è¾“å…¥å…ƒç»„å¿…é¡»åŒ…å«ä¸¤ä¸ªå…ƒç´ ï¼štext å’Œ voice')
            return inputs[0], inputs[1]
        elif isinstance(inputs, str):
            return inputs, "æ´¾è’™"
        else:
            raise ValueError('è¾“å…¥å¿…é¡»æ˜¯åŒ…å«æ–‡æœ¬å’Œè¯´è¯äººçš„å…ƒç»„ï¼Œæˆ–è€…å•ç‹¬çš„æ–‡æœ¬å­—ç¬¦ä¸²')

    def forward(self, inputs):
        text, voice = self.preprocess(inputs)
        audio = self.model.forward(text, voice)
        result = {
            'audio': audio.cpu().numpy(),
            'sample_rate': self.model.sampling_rate
        }
        return result

    def postprocess(self, inputs):
        return inputs

def setup_server():
    """è®¾ç½®å¹¶å¯åŠ¨æœåŠ¡å™¨"""
    try:
        script_dir = Path(__file__).parent.resolve()
        local_cache_dir = script_dir / "model_cache"
        local_cache_dir.mkdir(exist_ok=True)

        system = platform.system()
        TEMP_DIR = Path(os.getenv('TEMP')) / "hoyo_tts" / "output" if system == "Windows" else Path.home() / "Library" / "Caches" / "hoyo_tts" / "output"
        TEMP_DIR.mkdir(parents=True, exist_ok=True)

        print_step("æ­£åœ¨ä¸‹è½½æ¨¡å‹ï¼ˆåˆæ¬¡è¿è¡Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰...")
        model_dir = snapshot_download('Genius-Society/hoyoTTS', cache_dir=str(local_cache_dir))

        config_path = os.path.join(model_dir, 'configuration.json')
        config = {
            "model_dir": model_dir,
            "framework": "pytorch",
            "task": "text-to-speech",
            "pipeline": {
                "type": "hoyotts-speech-generation"
            },
            "model": {
                "type": "hoyotts",
                "duration_model": "DUR_78000.pth",
                "acoustic_model": "D_78000.pth",
                "vocoder_model": "G_78000.pth"
            }
        }

        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2)

        print_step("æ­£åœ¨åˆå§‹åŒ–è¯­éŸ³æ¨¡å‹...")
        inference = HoyoTTSPipeline(
            model_dir=model_dir,
            device='cuda' if torch.cuda.is_available() else 'cpu'
        )

        print_step("æµ‹è¯•è¯­éŸ³ç”Ÿæˆ...")
        test_text = "æµ‹è¯•æ–‡æœ¬"
        test_result = inference(test_text)
        if not isinstance(test_result, dict) or 'audio' not in test_result:
            raise ValueError("Pipeline æµ‹è¯•å¤±è´¥")
        print_success("Pipeline åˆ›å»ºå¹¶æµ‹è¯•æˆåŠŸ!")

        class SpeechRequest(BaseModel):
            prompt: str
            voice: str
            speed: Optional[float] = 1.0
            pitch: Optional[float] = 1.0
            pause: Optional[float] = 0.0
            style: Optional[int] = 0

        app = FastAPI(title="Hoyo TTS Server")

        app.add_middleware(
            CORSMiddleware,
            allow_origins=["*"],
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )

        app.mount("/audio", StaticFiles(directory=str(TEMP_DIR)), name="audio")

        @app.post("/v1/audio/speech")
        async def create_speech(request: SpeechRequest):
            unique_id = str(uuid.uuid4())[:8]
            output_path = TEMP_DIR / f"{unique_id}.wav"

            try:
                result = inference((request.prompt, request.voice))
                if not isinstance(result, dict) or 'audio' not in result:
                    raise ValueError("è¯­éŸ³ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ˜¯å¦æ­£ç¡®")
                sf.write(str(output_path), result['audio'], result['sample_rate'])
                audio_url = f"http://127.0.0.1:8000/audio/{unique_id}.wav"
                print_success(f"ç”ŸæˆæˆåŠŸ: {audio_url}")
                return JSONResponse({
                    "status": "success",
                    "audio_url": audio_url
                })
            except Exception as e:
                error_msg = str(e)
                print_error(f"ç”Ÿæˆå¤±è´¥: {error_msg}")
                raise HTTPException(status_code=500, detail=error_msg)

        @app.get("/health")
        async def health_check():
            return {"status": "healthy"}

        print_success("æœåŠ¡å™¨å¯åŠ¨ä¸­...")
        uvicorn.run(app, host="127.0.0.1", port=8000)

    except Exception as e:
        print_error(f"æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {str(e)}")
        print("\nå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("2. ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´ï¼ˆè‡³å°‘1GBï¼‰")
        print("3. å°è¯•é‡å¯ç”µè„‘åé‡è¯•")
        print("4. ä½¿ç”¨ç®¡ç†å‘˜æƒé™è¿è¡Œ")
        sys.exit(1)

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    print("\n=== Hoyo TTS è¯­éŸ³åˆæˆæœåŠ¡å™¨ ===")
    print("æœ¬ç¨‹åºå°†è‡ªåŠ¨é…ç½®å¹¶å¯åŠ¨è¯­éŸ³æœåŠ¡")
    print("é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼ˆçº¦600MBï¼‰ï¼Œè¯·è€å¿ƒç­‰å¾…")
    print("è¿è¡Œè¿‡ç¨‹ä¸­è¯·å‹¿å…³é—­æ­¤çª—å£\n")

    try:
        check_python()
        check_and_install_dependencies()
        setup_server()

    except KeyboardInterrupt:
        print("\n\nç¨‹åºå·²åœæ­¢ï¼ŒæŒ‰ Ctrl+C å†æ¬¡å°è¯•åœæ­¢ç¨‹åº")
        logging.info("ç¨‹åºå·²åœæ­¢")
        sys.exit(0)
    except OSError as e:
        print_error(f"æ“ä½œç³»ç»Ÿé”™è¯¯: {str(e)}")
        print("\nå¦‚æœé‡åˆ°é—®é¢˜ï¼Œå»ºè®®:")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("2. é‡å¯ç”µè„‘åé‡è¯•")
        print("3. ç¡®ä¿å®‰è£…äº†æœ€æ–°ç‰ˆPython")
        sys.exit(1)
    except RuntimeError as e:
        print_error(f"è¿è¡Œæ—¶é”™è¯¯: {str(e)}")
        print("\nå¦‚æœé‡åˆ°é—®é¢˜ï¼Œå»ºè®®:")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("2. é‡å¯ç”µè„‘åé‡è¯•")
        print("3. ç¡®ä¿å®‰è£…äº†æœ€æ–°ç‰ˆPython")
        sys.exit(1)
    except Exception as e:
        print_error(f"æœªçŸ¥é”™è¯¯: {str(e)}")
        print("\nå¦‚æœé‡åˆ°é—®é¢˜ï¼Œå»ºè®®:")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("2. é‡å¯ç”µè„‘åé‡è¯•")
        print("3. ç¡®ä¿å®‰è£…äº†æœ€æ–°ç‰ˆPython")
        sys.exit(1)

if __name__ == "__main__":
    main()
